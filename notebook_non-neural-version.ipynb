{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f41fdc-8c69-4448-9ad8-04c1874e1725",
   "metadata": {},
   "source": [
    "---\n",
    "### **<p style=\"text-align: center; text-decoration: underline;\">Natural Language Processing</p>**\n",
    "# **<p style=\"text-align: center;\">Practical: A bit of Morphological Warm up</p>**\n",
    "---\n",
    "\n",
    "> Realized by: *Zakaria Boulkhir* & *Omar Iken*.\n",
    "\n",
    "> Master 2, Data Science, Lille University.\n",
    "\n",
    "---\n",
    "\n",
    "### ■ __Overview__\n",
    "In this notebook, we will propose models for the shared-task task 0 problem. To do so, we will use the development data to design two models (a neural and a non neural) that given a lemma and a set of morphological attributes return the corresponding form.\n",
    "\n",
    "### ■ **<a name=\"content\">Contents</a>**\n",
    "\n",
    "- [1. Warm Up](#warmup)\n",
    "\n",
    "- [2. Actual Work](#actualWork)\n",
    "\n",
    "### ■ **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7a0775-1e53-4c08-bf31-bc8e23cdd395",
   "metadata": {},
   "outputs": [],
   "source": [
    "## numpy to handle arrays & matices\n",
    "import numpy as np\n",
    "\n",
    "## matplotlib & Seaborn to plot figures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## pandas to handle dataframes\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import codecs\n",
    "import os\n",
    "from utils.utils import *\n",
    "from utils.eval import *\n",
    "import unidecode\n",
    "\n",
    "## sklearn dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89771db-6da9-4372-a65d-c762f0c13f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------< Setting >------------#\n",
    "## set plots text font size & style\n",
    "sns.set(font_scale=1.2, style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfeed2f-02e6-492e-9986-4124a0a62325",
   "metadata": {},
   "source": [
    "### ■ **<a name=\"warmup\">1. Dataset</a>** [(&#8593;)](#content)\n",
    "The objective of this section is to write down a very simple system that predict morphological attributes. To do so, we will use the data available [here](https://github.com/sigmorphon2020/task0-data). Then, we will pick a language we do not speak, for instance *Akan (aka)*, and we explore the data. Of course our models should be applicable to other languages.\n",
    "\n",
    ">**Note:**  The choice of the language *Akan* is due to the fact that it covers most of the cases we will deal with in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eef3190-ac67-40a2-9675-c5655e3d613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 2793\n",
      "Number of testing samples : 763\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>form</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boro</td>\n",
       "      <td>bɛboroee</td>\n",
       "      <td>V;PST+IMMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tow .. mu</td>\n",
       "      <td>tow .. mu</td>\n",
       "      <td>V;HAB;PRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dum</td>\n",
       "      <td>dumee</td>\n",
       "      <td>V;HAB;PST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba</td>\n",
       "      <td>ammbɛba</td>\n",
       "      <td>V;NEG;PST+IMMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yi ayɛw</td>\n",
       "      <td>nnkɔyi ayɛwee</td>\n",
       "      <td>V;PRF;NEG;PRS;LGSPEC1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lemma           form             attributes\n",
       "0       boro       bɛboroee            V;PST+IMMED\n",
       "1  tow .. mu      tow .. mu              V;HAB;PRS\n",
       "2        dum          dumee              V;HAB;PST\n",
       "3         ba        ammbɛba        V;NEG;PST+IMMED\n",
       "4    yi ayɛw  nnkɔyi ayɛwee  V;PRF;NEG;PRS;LGSPEC1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## file path\n",
    "train_file = 'data/DEVELOPMENT-LANGUAGES/niger-congo/aka.trn'\n",
    "test_file = 'data/GOLD-TEST/aka.tst'\n",
    "\n",
    "## dataframe\n",
    "df_train = read_file(train_file)\n",
    "df_test = read_file(test_file)\n",
    "\n",
    "## number of training & testing samples\n",
    "n_train = df_train.shape[0]\n",
    "n_test = df_test.shape[0]\n",
    "print(f'Number of training samples: {n_train}')\n",
    "print(f'Number of testing samples : {n_test}')\n",
    "\n",
    "## dispaly some samples\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f38e05-5936-4c53-b126-af5117890a8f",
   "metadata": {},
   "source": [
    "**Unique Characters:** Get the unique the characters of the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fa0fe2-ad89-4460-9e22-7364e5ffc5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Number of unique characters: 23\n",
      "> Characters:  , ., a, b, d, e, f, g, h, i, k, m, n, o, p, r, s, t, u, w, y, ɔ, ɛ\n"
     ]
    }
   ],
   "source": [
    "## get the number of unique characters\n",
    "text = ''.join(df_train[['lemma', 'form']].to_numpy().flatten())\n",
    "\n",
    "## get (number of) unique characters\n",
    "unique_chars = sorted(set(text))\n",
    "n_chars = len(unique_chars)\n",
    "\n",
    "print(f\"> Number of unique characters: {n_chars}\\n> Characters: {', '.join(unique_chars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb2368-1c9f-48e4-a921-eee51aca90f5",
   "metadata": {},
   "source": [
    "**Morphological attributes:** histogram of different attributes, this will allow us to see which one is dominating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73fca13-83fd-40a8-8f58-da71b84270c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Number of unique morphological attributes: 16\n",
      "> Morphological attributes: FUT, HAB, HAB+PRF, HAB+PROG, IMP, LGSPEC1, NEG, NFIN, PRF, PROG, PRS, PRS+IMMED, PST, PST+IMMED, SBJV, V\n"
     ]
    }
   ],
   "source": [
    "## get unique morphological attributes\n",
    "morph_attrs = ';'.join(df_train['attributes'].to_list()).split(';')\n",
    "morph_attrs = np.asarray(morph_attrs)\n",
    "unique_attrs = sorted(set(morph_attrs)) ## sort to keep same order\n",
    "n_attrs = len(unique_attrs)\n",
    "\n",
    "print(f\"> Number of unique morphological attributes: {n_attrs}\\n> Morphological attributes: {', '.join(unique_attrs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f6876-cc9e-43b0-858a-422ac945775d",
   "metadata": {},
   "source": [
    "### ■ **<a name=\"section2\">2. First Approach: Bag of words (Characters)</a>** [(&#8593;)](#content)\n",
    "For this first simple approach, we use the bag-of-words method.\n",
    "The particularity of our proposed method is that we will use the bag-of-words method on characters instead of words (bag-of-characters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff431d84-567a-44e4-afd9-77795ce9cc0d",
   "metadata": {},
   "source": [
    "#### **2.1. Modeling the data**\n",
    "Bag-of-characters will allow us to have a feature space of fixed size, since the number of characters in each language is fixed unlike its set of words.\n",
    "Also, unlike the bag-of-words on words method, this method will allow us to capture all words, even on the test set.\n",
    "Therefore, an important step of this method consists of bringing all lemmas and forms to a fixed size (number of characters), in fact, in our case we compute the maximum possible number of characters for a lemma for a given language and we map all other words to that maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0692cddd-4360-4ccc-9993-1e88aa0bb023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FUT': 1,\n",
       " 'HAB': 2,\n",
       " 'HAB+PRF': 3,\n",
       " 'HAB+PROG': 4,\n",
       " 'IMP': 5,\n",
       " 'LGSPEC1': 6,\n",
       " 'NEG': 7,\n",
       " 'NFIN': 8,\n",
       " 'PRF': 9,\n",
       " 'PROG': 10,\n",
       " 'PRS': 11,\n",
       " 'PRS+IMMED': 12,\n",
       " 'PST': 13,\n",
       " 'PST+IMMED': 14,\n",
       " 'SBJV': 15,\n",
       " 'V': 16}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## bag of words for characters\n",
    "char_dict = dict(zip(unique_chars, range(1, len(unique_chars)+1)))\n",
    "inv_char_dict = {n:char for char, n in char_dict.items()}\n",
    "\n",
    "## bag of words for attributes\n",
    "attr_dict = {attr:i for i, attr in enumerate(unique_attrs, start=1)}\n",
    "attr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46815aa-b449-460a-a22d-5461f0dd31c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum possible number of character in a lemma: 9\n",
      "The maximum possible number of character in a form : 19\n",
      "The maximum possible number of attributes for a given lemma & form: 5\n"
     ]
    }
   ],
   "source": [
    "## compute maximum possible characters in a lemma and a form\n",
    "max_lemma_length = df_train['lemma'].apply(list).apply(len).max()\n",
    "max_form_length = df_train['form'].apply(lambda x: len(list(x))).max()\n",
    "\n",
    "## compute maximum possible number of attributes\n",
    "max_n_attrs = df_train['attributes'].apply(lambda x: len(x.split(';'))).max()\n",
    "\n",
    "## \n",
    "print(f'The maximum possible number of character in a lemma: {max_lemma_length}')\n",
    "print(f'The maximum possible number of character in a form : {max_form_length}')\n",
    "print(f'The maximum possible number of attributes for a given lemma & form: {max_n_attrs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e48765-42c4-40b2-a2f2-9745eda8bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(array, n, val):\n",
    "    \"\"\"to pad a given vector to size n with value val\"\"\"\n",
    "    return np.append(array, np.full(n - len(array), val))\n",
    "\n",
    "def vect2word(vect, char_dict):\n",
    "    word = ''.join([char_dict[i] for i in vect if i])\n",
    "    return word\n",
    "\n",
    "def create_trainset(lemmas, forms, attributes, max_lemma, max_form, max_attrs):\n",
    "    \"\"\"create a bag of words training set\"\"\"\n",
    "    ## create X and y train\n",
    "    X_train, y_train = [], []\n",
    "    for lemma, form, set_attrs in zip(lemmas, forms, attributes):\n",
    "        x, y = [], []\n",
    "        \n",
    "        l = []\n",
    "        for char in lemma:\n",
    "            l.append(char_dict[char])\n",
    "            \n",
    "        for char in form:\n",
    "            y.append(char_dict[char])\n",
    "\n",
    "        at = []\n",
    "        for attr in set_attrs:\n",
    "            at.append(attr_dict[attr])\n",
    "\n",
    "\n",
    "        x = np.append(pad(l, max_lemma, 0), pad(at, max_attrs, 0))\n",
    "        X_train.append(x)\n",
    "        y_train.append(pad(y, max_form, 0))\n",
    "        \n",
    "    return np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50cd0b4-ed53-482b-aa36-fccde9e42ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2793, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get training & test set\n",
    "X_train, y_train = create_trainset(df_train['lemma'].values,\n",
    "                                   df_train['form'].values, \n",
    "                                   df_train['attributes'].apply(lambda x:x.split(';')).values,\n",
    "                                   max_lemma_length, max_form_length, max_n_attrs)\n",
    "\n",
    "X_test, y_test = create_trainset(df_test['lemma'].values, \n",
    "                                 df_test['form'].values,\n",
    "                                 df_test['attributes'].apply(lambda x:x.split(';')).values, \n",
    "                                 max_lemma_length, max_form_length, max_n_attrs)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92631bfb-5f99-4c41-a7d8-768cd0696122",
   "metadata": {},
   "source": [
    "#### **2.2. Train & Evaluate the model**\n",
    "We mainly rely on Random Forest algorithms because they have shown promising results and we think they are suitable for our case, since we are working on a classification problem of sorts. Another interesting and very useful fact about Random Forests is their ability to perform multi-class classification on several features at the same time, i.e. we predict several features using a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47695a-5299-4129-aa0e-7c6390484013",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed365f70-758d-4661-8b0f-f688fd7a359c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Lanvenshtein distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rekɔbisa</td>\n",
       "      <td>rekɔbaaa</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kɔyiee</td>\n",
       "      <td>kɔyie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nna abɛkyiri</td>\n",
       "      <td>nna abɛhyina</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akɔtwe</td>\n",
       "      <td>akɔttw</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nna renyam</td>\n",
       "      <td>nna re</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           true     predicted Lanvenshtein distance\n",
       "0      rekɔbisa      rekɔbaaa                     2\n",
       "1        kɔyiee         kɔyie                     1\n",
       "2  nna abɛkyiri  nna abɛhyina                     3\n",
       "3        akɔtwe        akɔttw                     2\n",
       "4    nna renyam        nna re                     4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create & fit an RF model\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "## make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "## vects to words\n",
    "words_prediction = [vect2word(vect, inv_char_dict) for vect in y_pred]\n",
    "words_test = [vect2word(vect, inv_char_dict) for vect in y_test]\n",
    "\n",
    "## compute Lanvenshtein distance\n",
    "dist = [distance(word1, word2) for word1, word2 in zip(words_test, words_prediction)]\n",
    "df_pred = pd.DataFrame([words_test, words_prediction, dist], \n",
    "                       index=['true', 'predicted', 'Lanvenshtein distance']).T\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c382f0-b2aa-41c1-9601-3e66faf8db20",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce7cf39-0222-44a9-9e45-773b59bbdbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The word by word accuracy          : 0.06684141546526867\n",
      "- The character by character accuracy: 0.7578841743119266\n"
     ]
    }
   ],
   "source": [
    "print(f'- The word by word accuracy          : {word_accuracy(words_prediction, words_test)}')\n",
    "print(f'- The character by character accuracy: {character_accuracy(words_prediction, words_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895fd79-f1c8-4fb3-bf98-52f02710f904",
   "metadata": {},
   "source": [
    ">**Comments:**\n",
    "> - The model was able to learn the prefixes of most forms.\n",
    "> - The model is not as accurate on the body of the lemma.\n",
    "> - An interesting idea is to create a model that predicts the prefixes and suffixes of the form, and then put them together with the lamma to get the actual form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d7806-1893-4a66-8ded-a6235f7ed2cc",
   "metadata": {},
   "source": [
    "### ■ **<a name=\"section3\">3. Second Approach: Prefix-suffix-based approach</a>** [(&#8593;)](#content)\n",
    "For this second approach, we proposed a new method that attempts to predict the prefix and suffix of a given lemma and, by combining them with the lemma, obtain the actual form.\n",
    "To do this, we extract both the prefix and suffix of each form from the given lemma, and then associate with each prefix and suffix a number that will be predicted by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eb36dc-6ed9-46ff-8dd6-47593b4d3899",
   "metadata": {},
   "source": [
    "#### **3.1. Modeling the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8983c364-2d3f-4504-b58c-efb2cf43ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix(form, lemma):\n",
    "    \"\"\"return the prefix from the given form and lemma\"\"\"\n",
    "    if lemma in form:\n",
    "        idx = form.index(lemma)\n",
    "        return form[:idx]\n",
    "    return ''\n",
    "\n",
    "def get_suffix(form, lemma):\n",
    "    \"\"\"return the suffix from the given lemma and form\"\"\"\n",
    "    if lemma in form:\n",
    "        idx = form.index(lemma)\n",
    "        return form[idx + len(lemma):]\n",
    "    return ''\n",
    "\n",
    "def remove_prefix(form, prefix):\n",
    "    \"\"\"remove the prefix from the form\"\"\"\n",
    "    if form.startswith(prefix):\n",
    "        return form[len(prefix):]\n",
    "    return form\n",
    "\n",
    "def remove_suffix(form, suffix):\n",
    "    \"\"\"remove the suffix from the form\"\"\"\n",
    "    if suffix and form.endswith(suffix):\n",
    "        return form[:-len(suffix)]\n",
    "    return form\n",
    "\n",
    "def get_lemma(form, prefix, suffix):\n",
    "    \"\"\"return the lemma from the form given the prefix and the suffix\"\"\"\n",
    "    lemma = remove_suffix(form, suffix)\n",
    "    lemma = remove_prefix(lemma, prefix)\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b16a1af-55f4-4007-8875-3f9b77479eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>form</th>\n",
       "      <th>attributes</th>\n",
       "      <th>prefix</th>\n",
       "      <th>suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boro</td>\n",
       "      <td>bɛboroee</td>\n",
       "      <td>V;PST+IMMED</td>\n",
       "      <td>bɛ</td>\n",
       "      <td>ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tow .. mu</td>\n",
       "      <td>tow .. mu</td>\n",
       "      <td>V;HAB;PRS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dum</td>\n",
       "      <td>dumee</td>\n",
       "      <td>V;HAB;PST</td>\n",
       "      <td></td>\n",
       "      <td>ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba</td>\n",
       "      <td>ammbɛba</td>\n",
       "      <td>V;NEG;PST+IMMED</td>\n",
       "      <td>ammbɛ</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yi ayɛw</td>\n",
       "      <td>nnkɔyi ayɛwee</td>\n",
       "      <td>V;PRF;NEG;PRS;LGSPEC1</td>\n",
       "      <td>nnkɔ</td>\n",
       "      <td>ee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lemma           form             attributes prefix suffix\n",
       "0       boro       bɛboroee            V;PST+IMMED     bɛ     ee\n",
       "1  tow .. mu      tow .. mu              V;HAB;PRS              \n",
       "2        dum          dumee              V;HAB;PST            ee\n",
       "3         ba        ammbɛba        V;NEG;PST+IMMED  ammbɛ       \n",
       "4    yi ayɛw  nnkɔyi ayɛwee  V;PRF;NEG;PRS;LGSPEC1   nnkɔ     ee"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['prefix'] = df_train.apply(lambda col: get_prefix(col.form, col.lemma), axis=1)\n",
    "df_train['suffix'] = df_train.apply(lambda col: get_suffix(col.form, col.lemma), axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0b5cdd7-9b32-4ba7-b23c-b37118419d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2793, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create target array\n",
    "y_train = df_train[['prefix', 'suffix']].to_numpy()\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb623e-f174-4873-a717-40986c4dd2cb",
   "metadata": {},
   "source": [
    "#### **3.2. Training & Evaluating the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "834951dd-3f35-4eb4-b44f-050fe23b73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create & fit an RF model\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "## make predictions\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab8835bc-cfc1-4d75-8579-925e1e56fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X_test, y_pred):\n",
    "    pred_forms = []\n",
    "    for lemma, y in zip(X_test, y_pred):\n",
    "        prefix, suffix = y\n",
    "        form = prefix + lemma + suffix\n",
    "        pred_forms.append(form)\n",
    "    return pred_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a5a527d-03a5-4c31-9979-7f8d9f12759b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Lanvenshtein distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rekɔbisa</td>\n",
       "      <td>rekɔbisa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kɔyiee</td>\n",
       "      <td>kɔyiee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nna abɛkyiri</td>\n",
       "      <td>nna abɛkyiri</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akɔtwe</td>\n",
       "      <td>akɔtwe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nna renyam</td>\n",
       "      <td>nna renyam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           true     predicted Lanvenshtein distance\n",
       "0      rekɔbisa      rekɔbisa                     0\n",
       "1        kɔyiee        kɔyiee                     0\n",
       "2  nna abɛkyiri  nna abɛkyiri                     0\n",
       "3        akɔtwe        akɔtwe                     0\n",
       "4    nna renyam    nna renyam                     0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## vector to word\n",
    "words_test = [vect2word(vect, inv_char_dict) for vect in y_test]\n",
    "words_prediction = get_predictions(df_test['lemma'].to_numpy(), y_pred)\n",
    "\n",
    "## compute Lanvenshtein distance\n",
    "dist = [distance(word1, word2) for word1, word2 in zip(words_test, words_prediction)]\n",
    "df_pred = pd.DataFrame([words_test, words_prediction, dist], \n",
    "                       index=['true', 'predicted', 'Lanvenshtein distance']).T\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a89f3e24-b04a-4f5b-81a3-cd8f0a32a259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The word by word accuracy          : 0.8636959370904325\n",
      "- The character by character accuracy: 0.9683562428407789\n"
     ]
    }
   ],
   "source": [
    "print(f'- The word by word accuracy          : {word_accuracy(words_prediction, words_test)}')\n",
    "print(f'- The character by character accuracy: {character_accuracy(words_prediction, words_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47efdb-7d5b-4b55-8267-a560b23a9c3d",
   "metadata": {},
   "source": [
    "#### **3.3. Improving further**\n",
    "\n",
    "**Encode attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2fd402a-737b-45da-ab8b-83f5ef1cc108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded attributes shape: (2793, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FUT</th>\n",
       "      <th>HAB</th>\n",
       "      <th>HAB+PRF</th>\n",
       "      <th>HAB+PROG</th>\n",
       "      <th>IMP</th>\n",
       "      <th>LGSPEC1</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NFIN</th>\n",
       "      <th>PRF</th>\n",
       "      <th>PROG</th>\n",
       "      <th>PRS</th>\n",
       "      <th>PRS+IMMED</th>\n",
       "      <th>PST</th>\n",
       "      <th>PST+IMMED</th>\n",
       "      <th>SBJV</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FUT  HAB  HAB+PRF  HAB+PROG  IMP  LGSPEC1  NEG  NFIN  PRF  PROG  PRS  \\\n",
       "0    0    0        0         0    0        0    0     0    0     0    0   \n",
       "1    0    1        0         0    0        0    0     0    0     0    1   \n",
       "2    0    1        0         0    0        0    0     0    0     0    0   \n",
       "3    0    0        0         0    0        0    1     0    0     0    0   \n",
       "4    0    0        0         0    0        1    1     0    1     0    1   \n",
       "\n",
       "   PRS+IMMED  PST  PST+IMMED  SBJV  V  \n",
       "0          0    0          1     0  1  \n",
       "1          0    0          0     0  1  \n",
       "2          0    1          0     0  1  \n",
       "3          0    0          1     0  1  \n",
       "4          0    0          0     0  1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## bag of words for attributes\n",
    "attributes_dict = dict(zip(unique_attrs, range(n_attrs)))\n",
    "\n",
    "def encode_attributes(attributes, max_n_attrs, attributes_dict):\n",
    "    \"\"\"(multi-)onehot encoding for attributes\"\"\"\n",
    "    encoded = np.zeros(len(attributes_dict))\n",
    "    encoded[[attributes_dict[attr] for attr in attributes]] = 1\n",
    "    return encoded\n",
    "    \n",
    "## encode attributes   \n",
    "encoded_attributes = np.array([encode_attributes(attrs.split(';'), max_n_attrs, attributes_dict) for attrs in df_train['attributes'].to_list()])\n",
    "encoded_test_attributes = np.array([encode_attributes(attrs.split(';'), max_n_attrs, attributes_dict) for attrs in df_test['attributes'].to_list()])\n",
    "print(f'encoded attributes shape: {encoded_attributes.shape}')\n",
    "\n",
    "pd.DataFrame(encoded_attributes, columns=unique_attrs).astype('int').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64535b48-9dea-4c0e-9bf4-31b5ad546781",
   "metadata": {},
   "source": [
    "**Create new training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90a48116-eb53-4e20-8565-6321fe66e965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2793, 25)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## new training data\n",
    "new_X_train = np.concatenate((X_train[:, :max_lemma_length], encoded_attributes), axis=1)\n",
    "new_X_test = np.concatenate((X_test[:, :max_lemma_length], encoded_test_attributes), axis=1)\n",
    "new_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d654236-8ce8-4055-a9bb-18b9383486e6",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f08cdf7d-a1f2-4c13-87bc-4715fa4e8fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Lanvenshtein distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rekɔbisa</td>\n",
       "      <td>rekɔbisa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kɔyiee</td>\n",
       "      <td>kɔyie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nna abɛkyiri</td>\n",
       "      <td>nna abɛkyiri</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akɔtwe</td>\n",
       "      <td>akɔtwe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nna renyam</td>\n",
       "      <td>nna renyam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           true     predicted Lanvenshtein distance\n",
       "0      rekɔbisa      rekɔbisa                     0\n",
       "1        kɔyiee         kɔyie                     1\n",
       "2  nna abɛkyiri  nna abɛkyiri                     0\n",
       "3        akɔtwe        akɔtwe                     0\n",
       "4    nna renyam    nna renyam                     0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create & fit an RF model\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(new_X_train, y_train)\n",
    "\n",
    "## make predictions\n",
    "y_pred = clf.predict(new_X_test)\n",
    "\n",
    "## vects to words\n",
    "words_prediction = get_predictions(df_test['lemma'].to_numpy(), y_pred)\n",
    "words_test = [vect2word(vect, inv_char_dict) for vect in y_test]\n",
    "\n",
    "## compute Lanvenshtein distance\n",
    "dist = [distance(word1, word2) for word1, word2 in zip(words_test, words_prediction)]\n",
    "df_pred = pd.DataFrame([words_test, words_prediction, dist], \n",
    "                       index=['true', 'predicted', 'Lanvenshtein distance']).T\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41b1536a-8e75-49fd-a880-4564079ea13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The word by word accuracy          : 0.927916120576671\n",
      "- The character by character accuracy: 0.9887624261633771\n"
     ]
    }
   ],
   "source": [
    "print(f'- The word by word accuracy          : {word_accuracy(words_prediction, words_test)}')\n",
    "print(f'- The character by character accuracy: {character_accuracy(words_prediction, words_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56d709-e168-4877-a59a-ae34e40f036d",
   "metadata": {},
   "source": [
    ">**Comments:**\n",
    "- The improved version works pretty well...\n",
    "- BUT, what about languages or forms where there is a change in the whole lemma to a get a form, for instance a `lemma=waba` and `form=wada`.\n",
    "- We need a model that can capture this kind of information. It will allow us to predict the form of a lemma even if there structure is different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6496105-7a96-4fc3-9231-bb06361f72b7",
   "metadata": {},
   "source": [
    "### ■ **<a name=\"section4\">4. Third Approach: Beyond Prefix & Suffix</a>** [(&#8593;)](#content)\n",
    "The previously proposed method suffers when the lemma is not part of the body of the form. \n",
    "To solve this problem, we propose a new approach, which is in a way an improvement of the previous one.\n",
    "This new approach takes into account the root of a given lemma and form and tries to capture what changes between the two representations (lemma and form).\n",
    "\n",
    "#### **4.1. Modeling of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "097fdfcd-33c8-4c89-818f-87bf67149eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root(string_1, string_2):\n",
    "    \"\"\"return the root intersection of two strings\"\"\"\n",
    "    \n",
    "    if len(string_1) > len(string_2):\n",
    "        larger_s = string_1 \n",
    "        smaller_s = string_2\n",
    "    else:\n",
    "        larger_s = string_2\n",
    "        smaller_s = string_1\n",
    "        \n",
    "    inter = ''\n",
    "    for i in range(len(larger_s)):\n",
    "        for j in range(i, len(larger_s)+1):\n",
    "            if j - i < len(inter):\n",
    "                continue\n",
    "            part = larger_s[i:j]\n",
    "            \n",
    "            if part in smaller_s and len(part) > len(inter):\n",
    "                inter = part\n",
    "        \n",
    "    return inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d52391e0-1805-43fc-9bd6-039af9935049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>form</th>\n",
       "      <th>attributes</th>\n",
       "      <th>prefix</th>\n",
       "      <th>suffix</th>\n",
       "      <th>root</th>\n",
       "      <th>lemma_prefix</th>\n",
       "      <th>form_prefix</th>\n",
       "      <th>lemma_suffix</th>\n",
       "      <th>form_suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boro</td>\n",
       "      <td>bɛboroee</td>\n",
       "      <td>V;PST+IMMED</td>\n",
       "      <td>bɛ</td>\n",
       "      <td>ee</td>\n",
       "      <td>boro</td>\n",
       "      <td></td>\n",
       "      <td>bɛ</td>\n",
       "      <td></td>\n",
       "      <td>ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tow .. mu</td>\n",
       "      <td>tow .. mu</td>\n",
       "      <td>V;HAB;PRS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>tow .. mu</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dum</td>\n",
       "      <td>dumee</td>\n",
       "      <td>V;HAB;PST</td>\n",
       "      <td></td>\n",
       "      <td>ee</td>\n",
       "      <td>dum</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba</td>\n",
       "      <td>ammbɛba</td>\n",
       "      <td>V;NEG;PST+IMMED</td>\n",
       "      <td>ammbɛ</td>\n",
       "      <td></td>\n",
       "      <td>ba</td>\n",
       "      <td></td>\n",
       "      <td>ammbɛ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yi ayɛw</td>\n",
       "      <td>nnkɔyi ayɛwee</td>\n",
       "      <td>V;PRF;NEG;PRS;LGSPEC1</td>\n",
       "      <td>nnkɔ</td>\n",
       "      <td>ee</td>\n",
       "      <td>yi ayɛw</td>\n",
       "      <td></td>\n",
       "      <td>nnkɔ</td>\n",
       "      <td></td>\n",
       "      <td>ee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lemma           form             attributes prefix suffix       root  \\\n",
       "0       boro       bɛboroee            V;PST+IMMED     bɛ     ee       boro   \n",
       "1  tow .. mu      tow .. mu              V;HAB;PRS                tow .. mu   \n",
       "2        dum          dumee              V;HAB;PST            ee        dum   \n",
       "3         ba        ammbɛba        V;NEG;PST+IMMED  ammbɛ                ba   \n",
       "4    yi ayɛw  nnkɔyi ayɛwee  V;PRF;NEG;PRS;LGSPEC1   nnkɔ     ee    yi ayɛw   \n",
       "\n",
       "  lemma_prefix form_prefix lemma_suffix form_suffix  \n",
       "0                       bɛ                       ee  \n",
       "1                                                    \n",
       "2                                                ee  \n",
       "3                    ammbɛ                           \n",
       "4                     nnkɔ                       ee  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## extract root\n",
    "df_train['root'] = df_train.apply(lambda col: get_root(col.lemma, col.form), axis=1)\n",
    "\n",
    "## extract prefixes\n",
    "df_train['lemma_prefix'] = df_train.apply(lambda col: get_prefix(col.lemma, col.root), axis=1)\n",
    "df_train['form_prefix'] = df_train.apply(lambda col: get_prefix(col.form, col.root), axis=1)\n",
    "\n",
    "## extract suffixes\n",
    "df_train['lemma_suffix'] = df_train.apply(lambda col: get_suffix(col.lemma, col.root), axis=1)\n",
    "df_train['form_suffix'] = df_train.apply(lambda col: get_suffix(col.form, col.root), axis=1)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b667272-6aa8-42a0-9d0b-669d85ed520e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2793, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bag_of_chars(lemmas, max_lemma):\n",
    "    \"\"\"create a bag of words training set\"\"\"\n",
    "    ## create X and y train\n",
    "    X_train = []\n",
    "    for lemma in lemmas:\n",
    "        \n",
    "        x = []\n",
    "        for char in lemma:\n",
    "            x.append(char_dict[char])\n",
    "            \n",
    "        X_train.append(pad(x, max_lemma, 0))\n",
    "        \n",
    "    return np.array(X_train)\n",
    "\n",
    "## get training & test set\n",
    "X_train = bag_of_chars(df_train['lemma'].to_numpy(), max_lemma_length)\n",
    "X_test  = bag_of_chars(df_test['lemma'].to_numpy(), max_lemma_length)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bb80ab7-683e-4a8d-b650-9e85e5cbac4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2793, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## bag of words\n",
    "lemma_prefix_dict = dict(zip(df_train['lemma_prefix'].unique(), range(1, len(df_train['lemma_prefix'].unique())+1)))\n",
    "lemma_suffix_dict = dict(zip(df_train['lemma_suffix'].unique(), range(1, len(df_train['lemma_suffix'].unique())+1)))\n",
    "form_prefix_dict  = dict(zip(df_train['form_prefix'].unique(), range(1, len(df_train['form_prefix'].unique())+1)))\n",
    "form_suffix_dict  = dict(zip(df_train['form_suffix'].unique(), range(1, len(df_train['form_suffix'].unique())+1)))\n",
    "\n",
    "inv_form_pref_dict = {n:pref for pref, n in form_prefix_dict.items()}\n",
    "inv_form_suff_dict = {n:suff for suff, n in form_suffix_dict.items()}\n",
    "\n",
    "## encode roots, suffixes & prefixes\n",
    "max_length_root = df_train['root'].apply(len).max()\n",
    "encoded_roots = bag_of_chars(df_train['root'].to_list(), max_length_root)\n",
    "encoded_lemma_suffix = df_train['lemma_suffix'].apply(lemma_suffix_dict.get).to_numpy().reshape(-1, 1)\n",
    "encoded_form_suffix  = df_train['form_suffix'].apply(form_suffix_dict.get).to_numpy().reshape(-1, 1)\n",
    "encoded_lemma_prefix = df_train['lemma_prefix'].apply(lemma_prefix_dict.get).to_numpy().reshape(-1, 1)\n",
    "encoded_form_prefix  = df_train['form_prefix'].apply(form_prefix_dict.get).to_numpy().reshape(-1, 1)\n",
    "\n",
    "## create target labels\n",
    "y_train = np.concatenate((encoded_roots, encoded_lemma_prefix, encoded_form_prefix, encoded_lemma_suffix, encoded_form_suffix), axis=1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c006afc-6e99-404c-8353-6800901a0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create & fit the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "## make predictions\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7331b46-3855-480b-9495-28323521734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X_test, y_pred):\n",
    "    \n",
    "    predictions = []\n",
    "    for x, y in zip(X_test, y_pred):\n",
    "        root, lemma_pref, form_pref, lemma_suff, form_suff = y[:max_lemma_length], *y[max_lemma_length:]\n",
    "        pref = inv_form_pref_dict[form_pref] \n",
    "        suff = inv_form_suff_dict[form_suff]\n",
    "        form = pref + vect2word(root, inv_char_dict) + suff\n",
    "        predictions.append(form)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "023013b2-f197-4ea2-b489-109e79ce5977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Lanvenshtein distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rekɔbisa</td>\n",
       "      <td>bisa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kɔyiee</td>\n",
       "      <td>yi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nna abɛkyiri</td>\n",
       "      <td>kyiri</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akɔtwe</td>\n",
       "      <td>twe</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nna renyam</td>\n",
       "      <td>nnnyam</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           true predicted Lanvenshtein distance\n",
       "0      rekɔbisa      bisa                     4\n",
       "1        kɔyiee        yi                     4\n",
       "2  nna abɛkyiri     kyiri                     7\n",
       "3        akɔtwe       twe                     3\n",
       "4    nna renyam    nnnyam                     4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## vects to words\n",
    "words_prediction = get_predictions(X_test, y_pred)\n",
    "words_test = [vect2word(vect, inv_char_dict) for vect in y_test]\n",
    "\n",
    "## compute Lanvenshtein distance\n",
    "dist = [distance(word1, word2) for word1, word2 in zip(words_test, words_prediction)]\n",
    "df_pred = pd.DataFrame([words_test, words_prediction, dist], \n",
    "                       index=['true', 'predicted', 'Lanvenshtein distance']).T\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dcbba7e-de5b-4e22-896a-808e655edb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The word by word accuracy          : 0.027522935779816515\n",
      "- The character by character accuracy: 0.4822241183162685\n"
     ]
    }
   ],
   "source": [
    "print(f'- The word by word accuracy          : {word_accuracy(words_prediction, words_test)}')\n",
    "print(f'- The character by character accuracy: {character_accuracy(words_prediction, words_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61fca1-1148-4455-8837-fd0d5a8763b5",
   "metadata": {},
   "source": [
    "### **References** \n",
    "@article{vylomova2020sigmorphon, title={SIGMORPHON 2020 Shared Task 0: Typologically Diverse Morphological Inflection}, author={Vylomova, Ekaterina and White, Jennifer and Salesky, Elizabeth and Mielke, Sabrina J and Wu, Shijie and Ponti, Edoardo and Maudslay, Rowan Hall and Zmigrod, Ran and Valvoda, Josef and Toldova, Svetlana and others}, journal={SIGMORPHON 2020}, pages={1}, year={2020} }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60003da-2427-461a-96de-870555fa362e",
   "metadata": {},
   "source": [
    "---\n",
    "<p style=\"text-align: center;\">Copyright © 2021 Omar Ikne & Zakaria Boulkhir</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
